{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ULfvg6_wrytz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Um5ELarLr5cl",
    "outputId": "f752258b-a25f-4d56-a256-5994ff3183c2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrukEoF6r7sP"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/Kaggle sber bank/processed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>...</th>\n",
       "      <th>cafe_count_5000_price_2500</th>\n",
       "      <th>cafe_count_5000_price_4000</th>\n",
       "      <th>cafe_count_5000_price_high</th>\n",
       "      <th>big_church_count_5000</th>\n",
       "      <th>church_count_5000</th>\n",
       "      <th>mosque_count_5000</th>\n",
       "      <th>leisure_count_5000</th>\n",
       "      <th>sport_count_5000</th>\n",
       "      <th>market_count_5000</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.567592</td>\n",
       "      <td>1.83439</td>\n",
       "      <td>2716.784531</td>\n",
       "      <td>1.900844</td>\n",
       "      <td>6.543995</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>5850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.567592</td>\n",
       "      <td>1.83439</td>\n",
       "      <td>2716.784531</td>\n",
       "      <td>1.900844</td>\n",
       "      <td>6.543995</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "      <td>6000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>43.0</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.567592</td>\n",
       "      <td>1.83439</td>\n",
       "      <td>2716.784531</td>\n",
       "      <td>1.900844</td>\n",
       "      <td>6.543995</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>10</td>\n",
       "      <td>5700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.567592</td>\n",
       "      <td>1.83439</td>\n",
       "      <td>2716.784531</td>\n",
       "      <td>1.900844</td>\n",
       "      <td>6.543995</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>13100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.00000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.567592</td>\n",
       "      <td>1.83439</td>\n",
       "      <td>2716.784531</td>\n",
       "      <td>1.900844</td>\n",
       "      <td>6.543995</td>\n",
       "      <td>...</td>\n",
       "      <td>319</td>\n",
       "      <td>108</td>\n",
       "      <td>17</td>\n",
       "      <td>135</td>\n",
       "      <td>236</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>195</td>\n",
       "      <td>14</td>\n",
       "      <td>16331452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30466</td>\n",
       "      <td>30466</td>\n",
       "      <td>30469</td>\n",
       "      <td>44.0</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>6</td>\n",
       "      <td>7400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30467</td>\n",
       "      <td>30467</td>\n",
       "      <td>30470</td>\n",
       "      <td>86.0</td>\n",
       "      <td>59.00000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1935.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>313</td>\n",
       "      <td>128</td>\n",
       "      <td>24</td>\n",
       "      <td>98</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>171</td>\n",
       "      <td>15</td>\n",
       "      <td>25000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30468</td>\n",
       "      <td>30468</td>\n",
       "      <td>30471</td>\n",
       "      <td>45.0</td>\n",
       "      <td>34.03346</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2716.784531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6970959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30469</td>\n",
       "      <td>30469</td>\n",
       "      <td>30472</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>7</td>\n",
       "      <td>13500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30470</td>\n",
       "      <td>30470</td>\n",
       "      <td>30473</td>\n",
       "      <td>43.0</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1968.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>10</td>\n",
       "      <td>5600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30471 rows Ã— 291 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id  full_sq   life_sq  floor  max_floor  material  \\\n",
       "0               0      1     43.0  27.00000    4.0  12.567592   1.83439   \n",
       "1               1      2     34.0  19.00000    3.0  12.567592   1.83439   \n",
       "2               2      3     43.0  29.00000    2.0  12.567592   1.83439   \n",
       "3               3      4     89.0  50.00000    9.0  12.567592   1.83439   \n",
       "4               4      5     77.0  77.00000    4.0  12.567592   1.83439   \n",
       "...           ...    ...      ...       ...    ...        ...       ...   \n",
       "30466       30466  30469     44.0  27.00000    7.0   9.000000   1.00000   \n",
       "30467       30467  30470     86.0  59.00000    3.0   9.000000   2.00000   \n",
       "30468       30468  30471     45.0  34.03346   10.0  20.000000   1.00000   \n",
       "30469       30469  30472     64.0  32.00000    5.0  15.000000   1.00000   \n",
       "30470       30470  30473     43.0  28.00000    1.0   9.000000   1.00000   \n",
       "\n",
       "        build_year  num_room   kitch_sq  ...  cafe_count_5000_price_2500  \\\n",
       "0      2716.784531  1.900844   6.543995  ...                           9   \n",
       "1      2716.784531  1.900844   6.543995  ...                          15   \n",
       "2      2716.784531  1.900844   6.543995  ...                          10   \n",
       "3      2716.784531  1.900844   6.543995  ...                          11   \n",
       "4      2716.784531  1.900844   6.543995  ...                         319   \n",
       "...            ...       ...        ...  ...                         ...   \n",
       "30466  1975.000000  2.000000   6.000000  ...                          15   \n",
       "30467  1935.000000  4.000000  10.000000  ...                         313   \n",
       "30468  2716.784531  1.000000   1.000000  ...                           1   \n",
       "30469  2003.000000  2.000000  11.000000  ...                          22   \n",
       "30470  1968.000000  2.000000   6.000000  ...                           5   \n",
       "\n",
       "       cafe_count_5000_price_4000  cafe_count_5000_price_high  \\\n",
       "0                               4                           0   \n",
       "1                               3                           0   \n",
       "2                               3                           0   \n",
       "3                               2                           1   \n",
       "4                             108                          17   \n",
       "...                           ...                         ...   \n",
       "30466                           5                           0   \n",
       "30467                         128                          24   \n",
       "30468                           1                           0   \n",
       "30469                           1                           1   \n",
       "30470                           2                           0   \n",
       "\n",
       "       big_church_count_5000  church_count_5000  mosque_count_5000  \\\n",
       "0                         13                 22                  1   \n",
       "1                         15                 29                  1   \n",
       "2                         11                 27                  0   \n",
       "3                          4                  4                  0   \n",
       "4                        135                236                  2   \n",
       "...                      ...                ...                ...   \n",
       "30466                     15                 26                  1   \n",
       "30467                     98                182                  1   \n",
       "30468                      2                 12                  0   \n",
       "30469                      6                 31                  1   \n",
       "30470                      7                 16                  0   \n",
       "\n",
       "       leisure_count_5000  sport_count_5000  market_count_5000  price_doc  \n",
       "0                       0                52                  4    5850000  \n",
       "1                      10                66                 14    6000000  \n",
       "2                       4                67                 10    5700000  \n",
       "3                       0                26                  3   13100000  \n",
       "4                      91               195                 14   16331452  \n",
       "...                   ...               ...                ...        ...  \n",
       "30466                   2                84                  6    7400000  \n",
       "30467                  82               171                 15   25000000  \n",
       "30468                   1                11                  1    6970959  \n",
       "30469                   4                65                  7   13500000  \n",
       "30470                   9                54                 10    5600000  \n",
       "\n",
       "[30471 rows x 291 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Features, labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 8.07360120e-03, ...,\n",
       "        0.00000000e+00, 2.38532110e-01, 1.90476190e-01],\n",
       "       [3.28191664e-05, 3.28170123e-05, 6.38377769e-03, ...,\n",
       "        9.43396226e-02, 3.02752294e-01, 6.66666667e-01],\n",
       "       [6.56383328e-05, 6.56340247e-05, 8.07360120e-03, ...,\n",
       "        3.77358491e-02, 3.07339450e-01, 4.76190476e-01],\n",
       "       ...,\n",
       "       [9.99934362e-01, 9.99934366e-01, 8.44911754e-03, ...,\n",
       "        9.43396226e-03, 5.04587156e-02, 4.76190476e-02],\n",
       "       [9.99967181e-01, 9.99967183e-01, 1.20165227e-02, ...,\n",
       "        3.77358491e-02, 2.98165138e-01, 3.33333333e-01],\n",
       "       [1.00000000e+00, 1.00000000e+00, 8.07360120e-03, ...,\n",
       "        8.49056604e-02, 2.47706422e-01, 4.76190476e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30471 entries, 0 to 30470\n",
      "Columns: 291 entries, Unnamed: 0 to price_doc\n",
      "dtypes: float64(121), int64(170)\n",
      "memory usage: 67.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\iad7kor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iad7kor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iad7kor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(290,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\iad7kor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iad7kor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iad7kor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\iad7kor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iad7kor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iad7kor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 21329 samples, validate on 9142 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\iad7kor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iad7kor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iad7kor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iad7kor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iad7kor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "21329/21329 [==============================] - 8s 380us/step - loss: -113402578.5597 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "21329/21329 [==============================] - 1s 70us/step - loss: -113538748.5846 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "21329/21329 [==============================] - 1s 65us/step - loss: -113538748.5193 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "21329/21329 [==============================] - 1s 60us/step - loss: -113538748.5636 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "21329/21329 [==============================] - 1s 63us/step - loss: -113538748.4210 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "21329/21329 [==============================] - 1s 61us/step - loss: -113538748.4593 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "21329/21329 [==============================] - 1s 58us/step - loss: -113538748.5470 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "21329/21329 [==============================] - 1s 63us/step - loss: -113538748.4173 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "21329/21329 [==============================] - 2s 77us/step - loss: -113538748.6029 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "21329/21329 [==============================] - 1s 67us/step - loss: -113538748.7458 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "21329/21329 [==============================] - 1s 64us/step - loss: -113538748.4349 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "21329/21329 [==============================] - 2s 72us/step - loss: -113538748.4949 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "21329/21329 [==============================] - 1s 61us/step - loss: -113538748.3978 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "21329/21329 [==============================] - 1s 60us/step - loss: -113538748.6093 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "21329/21329 [==============================] - 2s 75us/step - loss: -113538748.2729 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "21329/21329 [==============================] - 1s 70us/step - loss: -113538748.2065 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "21329/21329 [==============================] - 1s 61us/step - loss: -113538748.7353 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "21329/21329 [==============================] - 1s 62us/step - loss: -113538748.6701 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "21329/21329 [==============================] - 1s 70us/step - loss: -113538748.3790 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "21329/21329 [==============================] - 2s 73us/step - loss: -113538748.3929 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "21329/21329 [==============================] - 1s 68us/step - loss: -113538748.4210 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "21329/21329 [==============================] - 1s 59us/step - loss: -113538748.5928 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "21329/21329 [==============================] - 2s 74us/step - loss: -113538748.1742 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "21329/21329 [==============================] - 1s 67us/step - loss: -113538748.3040 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "21329/21329 [==============================] - 1s 65us/step - loss: -113538748.3670 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "21329/21329 [==============================] - 1s 63us/step - loss: -113538748.2522 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "21329/21329 [==============================] - 1s 69us/step - loss: -113538748.7972 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "21329/21329 [==============================] - 1s 65us/step - loss: -113538748.4720 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "21329/21329 [==============================] - 2s 72us/step - loss: -113538748.2444 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "21329/21329 [==============================] - 2s 72us/step - loss: -113538748.5358 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "21329/21329 [==============================] - 2s 71us/step - loss: -113538748.4942 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "21329/21329 [==============================] - 1s 67us/step - loss: -113538748.4780 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "21329/21329 [==============================] - 1s 66us/step - loss: -113538748.5973 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "21329/21329 [==============================] - 1s 69us/step - loss: -113538748.5684 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "21329/21329 [==============================] - 1s 66us/step - loss: -113538748.4428 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "21329/21329 [==============================] - 2s 74us/step - loss: -113538748.4402 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "21329/21329 [==============================] - 2s 73us/step - loss: -113538748.4098 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "21329/21329 [==============================] - 1s 66us/step - loss: -113538748.4762 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21329/21329 [==============================] - 1s 62us/step - loss: -113538748.5110 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "21329/21329 [==============================] - 1s 63us/step - loss: -113538748.8164 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "21329/21329 [==============================] - 1s 59us/step - loss: -113538748.4690 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "21329/21329 [==============================] - 1s 67us/step - loss: -113538748.1611 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "21329/21329 [==============================] - 1s 58us/step - loss: -113538748.6048 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "21329/21329 [==============================] - 1s 66us/step - loss: -113538748.2912 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "21329/21329 [==============================] - 1s 63us/step - loss: -113538748.6386 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "21329/21329 [==============================] - 1s 60us/step - loss: -113538748.4098 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "21329/21329 [==============================] - 1s 56us/step - loss: -113538748.7762 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "21329/21329 [==============================] - 1s 61us/step - loss: -113538748.4191 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "21329/21329 [==============================] - 1s 59us/step - loss: -113538748.3700 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "21329/21329 [==============================] - 1s 66us/step - loss: -113538748.4878 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "21329/21329 [==============================] - 1s 67us/step - loss: -113538748.2567 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "21329/21329 [==============================] - 1s 58us/step - loss: -113538748.3921 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "21329/21329 [==============================] - 1s 62us/step - loss: -113538748.3205 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "21329/21329 [==============================] - 1s 69us/step - loss: -113538748.3910 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "21329/21329 [==============================] - 1s 63us/step - loss: -113538748.8085 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "21329/21329 [==============================] - 1s 61us/step - loss: -113538748.5924 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "21329/21329 [==============================] - 1s 63us/step - loss: -113538748.6648 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "21329/21329 [==============================] - 1s 65us/step - loss: -113538748.7417 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "21329/21329 [==============================] - 1s 65us/step - loss: -113538748.6168 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "21329/21329 [==============================] - 1s 55us/step - loss: -113538748.5328 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "21329/21329 [==============================] - 1s 53us/step - loss: -113538748.2804 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "21329/21329 [==============================] - 1s 57us/step - loss: -113538748.4368 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "21329/21329 [==============================] - 1s 64us/step - loss: -113538748.6888 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "21329/21329 [==============================] - 1s 65us/step - loss: -113538748.5988 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "21329/21329 [==============================] - 1s 62us/step - loss: -113538748.6783 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "21329/21329 [==============================] - 1s 57us/step - loss: -113538748.4915 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "21329/21329 [==============================] - 1s 59us/step - loss: -113538748.7050 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "21329/21329 [==============================] - 1s 65us/step - loss: -113538748.2871 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "21329/21329 [==============================] - 1s 59us/step - loss: -113538748.6101 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "21329/21329 [==============================] - 1s 62us/step - loss: -113538748.5898 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "21329/21329 [==============================] - 1s 58us/step - loss: -113538748.6873 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "21329/21329 [==============================] - 1s 66us/step - loss: -113538748.5493 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "21329/21329 [==============================] - 1s 67us/step - loss: -113538748.3719 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "21329/21329 [==============================] - 2s 74us/step - loss: -113538748.1843 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "21329/21329 [==============================] - 1s 62us/step - loss: -113538748.1693 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "21329/21329 [==============================] - 1s 61us/step - loss: -113538748.5587 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "21329/21329 [==============================] - 1s 63us/step - loss: -113538748.3614 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "21329/21329 [==============================] - 1s 60us/step - loss: -113538748.8122 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "21329/21329 [==============================] - 1s 61us/step - loss: -113538748.4477 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "21329/21329 [==============================] - 1s 62us/step - loss: -113538748.4158 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "21329/21329 [==============================] - 1s 66us/step - loss: -113538748.4889 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "21329/21329 [==============================] - 1s 70us/step - loss: -113538748.5159 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "21329/21329 [==============================] - 1s 61us/step - loss: -113538748.4518 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "21329/21329 [==============================] - 1s 60us/step - loss: -113538748.3393 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "21329/21329 [==============================] - 1s 63us/step - loss: -113538748.5696 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "21329/21329 [==============================] - 1s 64us/step - loss: -113538748.4019 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "21329/21329 [==============================] - 1s 63us/step - loss: -113538748.3678 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "21329/21329 [==============================] - 1s 64us/step - loss: -113538748.5594 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "21329/21329 [==============================] - 1s 56us/step - loss: -113538748.4840 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "21329/21329 [==============================] - 1s 60us/step - loss: -113538748.2050 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "21329/21329 [==============================] - 1s 68us/step - loss: -113538748.6442 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "21329/21329 [==============================] - 1s 52us/step - loss: -113538748.6581 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "21329/21329 [==============================] - 1s 54us/step - loss: -113538748.6326 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "21329/21329 [==============================] - 1s 56us/step - loss: -113538748.3813 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "21329/21329 [==============================] - 1s 54us/step - loss: -113538748.4233 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "21329/21329 [==============================] - 1s 54us/step - loss: -113538748.6393 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "21329/21329 [==============================] - 1s 54us/step - loss: -113538748.4402 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "21329/21329 [==============================] - 1s 53us/step - loss: -113538748.6382 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "21329/21329 [==============================] - 1s 56us/step - loss: -113538748.4882 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "21329/21329 [==============================] - 1s 60us/step - loss: -113538748.6247 - acc: 0.0000e+00 - val_loss: -113603425.4264 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_val_and_test, Y_val_and_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_val_and_test, Y_val_and_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sberbank Russian Housing Market Kaggle  NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
